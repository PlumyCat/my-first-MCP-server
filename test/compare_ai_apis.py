#!/usr/bin/env python3
"""
Comparaison entre Claude et Azure OpenAI avec le serveur MCP
Teste les deux APIs c√¥te √† c√¥te avec les m√™mes donn√©es m√©t√©o
"""

import os
import asyncio
import json
import subprocess
import time
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

print("‚ö° COMPARAISON CLAUDE vs AZURE OPENAI")
print("=" * 60)

# V√©rifier les configurations
claude_available = bool(os.getenv('ANTHROPIC_API_KEY'))
azure_available = all(os.getenv(var) for var in [
    'AZURE_OPENAI_API_KEY', 'AZURE_OPENAI_ENDPOINT', 'AZURE_OPENAI_DEPLOYMENT_NAME'
])

print(f"üß† Claude API: {'‚úÖ Disponible' if claude_available else '‚ùå Non configur√©'}")
print(f"ü§ñ Azure OpenAI: {'‚úÖ Disponible' if azure_available else '‚ùå Non configur√©'}")

if not claude_available and not azure_available:
    print("‚ùå Aucune API configur√©e - configurez au moins une API dans .env")
    exit(1)

# Imports conditionnels
try:
    import anthropic
    ANTHROPIC_LIB = True
except ImportError:
    ANTHROPIC_LIB = False
    if claude_available:
        print("‚ö†Ô∏è pip install anthropic requis pour Claude")

try:
    import openai
    OPENAI_LIB = True
except ImportError:
    OPENAI_LIB = False
    if azure_available:
        print("‚ö†Ô∏è pip install openai requis pour Azure OpenAI")


class MCPWeatherServer:
    """Gestionnaire du serveur MCP Weather r√©utilisable"""
    
    def __init__(self, workspace_path: str = None):
        self.workspace_path = workspace_path or os.getcwd()
        self.process = None
        self.message_id = 0
        self.initialized = False
        
    def get_next_id(self):
        self.message_id += 1
        return self.message_id
    
    async def start(self) -> bool:
        try:
            env = os.environ.copy()
            env["PYTHONPATH"] = self.workspace_path
            env["PYTHONUNBUFFERED"] = "1"
            
            self.process = await asyncio.create_subprocess_exec(
                "python", "-m", "src.main",
                cwd=self.workspace_path,
                env=env,
                stdin=asyncio.subprocess.PIPE,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            return True
        except Exception:
            return False
    
    async def send_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        if not self.process:
            return {"error": "Server not started"}
        
        try:
            message_json = json.dumps(message) + "\\n"
            self.process.stdin.write(message_json.encode())
            await self.process.stdin.drain()
            
            response_line = await asyncio.wait_for(
                self.process.stdout.readline(), timeout=10.0
            )
            
            if response_line:
                return json.loads(response_line.decode().strip())
            else:
                return {"error": "No response"}
        except Exception as e:
            return {"error": str(e)}
    
    async def send_notification(self, method: str, params: Dict[str, Any] = None):
        notification = {"jsonrpc": "2.0", "method": method}
        if params is not None:
            notification["params"] = params
        
        try:
            notification_json = json.dumps(notification) + "\\n"
            self.process.stdin.write(notification_json.encode())
            await self.process.stdin.drain()
        except Exception:
            pass
    
    async def initialize(self) -> bool:
        try:
            init_message = {
                "jsonrpc": "2.0",
                "id": self.get_next_id(),
                "method": "initialize",
                "params": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {"tools": {}},
                    "clientInfo": {"name": "comparison-test", "version": "1.0.0"}
                }
            }
            
            init_response = await self.send_message(init_message)
            if "error" in init_response:
                return False
            
            await self.send_notification("notifications/initialized")
            await asyncio.sleep(0.5)
            
            self.initialized = True
            return True
        except Exception:
            return False
    
    async def get_weather(self, city: str, unit: str = "celsius") -> Dict[str, Any]:
        if not self.initialized:
            return {"success": False, "error": "Not initialized"}
        
        try:
            call_message = {
                "jsonrpc": "2.0",
                "id": self.get_next_id(),
                "method": "tools/call",
                "params": {
                    "name": "get_weather",
                    "arguments": {"city": city, "unit": unit}
                }
            }
            
            response = await self.send_message(call_message)
            
            if "result" in response:
                result = response["result"]
                if "content" in result and isinstance(result["content"], list):
                    if len(result["content"]) > 0:
                        text_content = result["content"][0].get("text", "")
                        if text_content:
                            return json.loads(text_content)
            
            return {"success": False, "error": "Invalid response format"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def stop(self):
        if self.process:
            self.process.terminate()
            try:
                await asyncio.wait_for(self.process.wait(), timeout=3.0)
            except asyncio.TimeoutError:
                self.process.kill()


class AIComparator:
    """Comparateur entre Claude et Azure OpenAI"""
    
    def __init__(self):
        self.mcp_server = None
        self.claude_client = None
        self.azure_client = None
        self.azure_deployment = None
        
        # Initialiser les clients disponibles
        if claude_available and ANTHROPIC_LIB:
            self.claude_client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
            print("‚úÖ Client Claude initialis√©")
        
        if azure_available and OPENAI_LIB:
            self.azure_client = openai.AzureOpenAI(
                api_key=os.getenv('AZURE_OPENAI_API_KEY'),
                api_version=os.getenv('AZURE_OPENAI_API_VERSION', '2024-05-01-preview'),
                azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')
            )
            self.azure_deployment = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')
            print("‚úÖ Client Azure OpenAI initialis√©")
    
    async def setup_mcp_server(self):
        """Configure le serveur MCP partag√©"""
        print("üöÄ D√©marrage du serveur MCP...")
        self.mcp_server = MCPWeatherServer()
        
        if not await self.mcp_server.start():
            raise Exception("Impossible de d√©marrer le serveur MCP")
        
        await asyncio.sleep(1)
        
        if not await self.mcp_server.initialize():
            raise Exception("Impossible d'initialiser MCP")
        
        print("‚úÖ Serveur MCP pr√™t pour les comparaisons")
    
    async def get_weather_context(self, cities: List[str]) -> str:
        """R√©cup√®re le contexte m√©t√©o pour toutes les villes"""
        weather_data = {}
        
        for city in cities:
            result = await self.mcp_server.get_weather(city)
            if result.get("success"):
                weather_data[city] = result["data"]
            else:
                weather_data[city] = {"error": result.get("error", "Unknown error")}
        
        # Construire le contexte
        weather_context = "Donn√©es m√©t√©o actuelles (via serveur MCP):\\n"
        for city, data in weather_data.items():
            if "error" not in data:
                weather_context += f"\\n{city}:"
                weather_context += f"\\n- Temp√©rature: {data['temperature']}{data['unit']}"
                weather_context += f"\\n- Conditions: {data['condition']}"
                weather_context += f"\\n- Humidit√©: {data['humidity']}%"
                weather_context += f"\\n- Vent: {data['wind_speed']} km/h"
                weather_context += f"\\n- Pression: {data['pressure']} hPa"
                if data.get('forecast'):
                    forecast = data['forecast'][0]
                    weather_context += f"\\n- Pr√©vision: {forecast['day']} {forecast['high']}¬∞-{forecast['low']}¬∞ {forecast['condition']}"
            else:
                weather_context += f"\\n{city}: Erreur - {data['error']}"
        
        return weather_context
    
    async def ask_claude(self, question: str, weather_context: str) -> Optional[str]:
        """Pose une question √† Claude"""
        if not self.claude_client:
            return None
        
        try:
            response = self.claude_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1000,
                messages=[
                    {
                        "role": "user",
                        "content": f"{weather_context}\\n\\nQuestion: {question}"
                    }
                ]
            )
            return response.content[0].text
        except Exception as e:
            return f"Erreur Claude: {e}"
    
    async def ask_azure(self, question: str, weather_context: str) -> Optional[str]:
        """Pose une question √† Azure OpenAI"""
        if not self.azure_client:
            return None
        
        try:
            response = self.azure_client.chat.completions.create(
                model=self.azure_deployment,
                messages=[
                    {
                        "role": "system",
                        "content": "Tu es un assistant m√©t√©o expert. R√©ponds de mani√®re pr√©cise et utile bas√© sur les donn√©es m√©t√©o fournies."
                    },
                    {
                        "role": "user",
                        "content": f"{weather_context}\\n\\nQuestion: {question}"
                    }
                ],
                max_tokens=1000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Erreur Azure: {e}"
    
    async def compare_responses(self, question: str, cities: List[str]):
        """Compare les r√©ponses des deux IA"""
        print(f"\\n‚ùì Question: {question}")
        print(f"üåç Villes: {', '.join(cities)}")
        print("-" * 60)
        
        # R√©cup√©rer le contexte m√©t√©o
        weather_context = await self.get_weather_context(cities)
        
        # Afficher les donn√©es m√©t√©o
        print("üå§Ô∏è Donn√©es m√©t√©o r√©cup√©r√©es:")
        for city in cities:
            result = await self.mcp_server.get_weather(city)
            if result.get("success"):
                data = result["data"]
                print(f"   {city}: {data['temperature']}{data['unit']}, {data['condition']}")
            else:
                print(f"   {city}: Erreur")
        
        results = {}
        
        # Test Claude
        if self.claude_client:
            print("\\nüß† Test Claude...")
            start_time = time.time()
            claude_response = await self.ask_claude(question, weather_context)
            claude_time = time.time() - start_time
            
            results['claude'] = {
                'response': claude_response,
                'time': claude_time,
                'length': len(claude_response) if claude_response else 0
            }
        
        # Test Azure OpenAI
        if self.azure_client:
            print("ü§ñ Test Azure OpenAI...")
            start_time = time.time()
            azure_response = await self.ask_azure(question, weather_context)
            azure_time = time.time() - start_time
            
            results['azure'] = {
                'response': azure_response,
                'time': azure_time,
                'length': len(azure_response) if azure_response else 0
            }
        
        # Afficher les r√©sultats
        if 'claude' in results:
            print(f"\\nüß† CLAUDE ({results['claude']['time']:.2f}s, {results['claude']['length']} chars):")
            print("‚îÄ" * 40)
            self._print_formatted_response(results['claude']['response'])
        
        if 'azure' in results:
            print(f"\\nü§ñ AZURE OPENAI ({results['azure']['time']:.2f}s, {results['azure']['length']} chars):")
            print("‚îÄ" * 40)
            self._print_formatted_response(results['azure']['response'])
        
        # Comparaison rapide
        if len(results) == 2:
            print(f"\\n‚ö° COMPARAISON RAPIDE:")
            claude_faster = results['claude']['time'] < results['azure']['time']
            claude_longer = results['claude']['length'] > results['azure']['length']
            
            print(f"   üèÉ Plus rapide: {'Claude' if claude_faster else 'Azure'}")
            print(f"   üìù Plus d√©taill√©: {'Claude' if claude_longer else 'Azure'}")
            print(f"   ‚è±Ô∏è √âcart temps: {abs(results['claude']['time'] - results['azure']['time']):.2f}s")
        
        return results
    
    def _print_formatted_response(self, response: str):
        """Affiche une r√©ponse format√©e"""
        if not response:
            print("   (Aucune r√©ponse)")
            return
        
        lines = response.split('\\n')
        for line in lines:
            if len(line) > 75:
                words = line.split(' ')
                current_line = ""
                for word in words:
                    if len(current_line + word) > 72:
                        print(f"   {current_line.strip()}")
                        current_line = word + " "
                    else:
                        current_line += word + " "
                if current_line.strip():
                    print(f"   {current_line.strip()}")
            else:
                print(f"   {line}")
    
    async def cleanup(self):
        """Nettoie les ressources"""
        if self.mcp_server:
            await self.mcp_server.stop()


async def run_comparison():
    """Ex√©cute la comparaison compl√®te"""
    
    comparator = AIComparator()
    
    try:
        await comparator.setup_mcp_server()
        
        # Questions de test comparatives
        test_scenarios = [
            {
                "question": "Quelle ville est id√©ale pour une promenade aujourd'hui ?",
                "cities": ["Paris", "London", "Madrid"]
            },
            {
                "question": "Dois-je reporter mon pique-nique pr√©vu √† New York ?",
                "cities": ["New York"]
            },
            {
                "question": "Compare la m√©t√©o entre h√©misph√®res nord et sud",
                "cities": ["Tokyo", "Sydney"]
            },
            {
                "question": "Planifie ma journ√©e parfaite √† Berlin selon la m√©t√©o",
                "cities": ["Berlin"]
            }
        ]
        
        print(f"\\nüéØ COMPARAISON sur {len(test_scenarios)} sc√©narios")
        print("=" * 60)
        
        all_results = []
        
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"\\nüìã SC√âNARIO {i}/{len(test_scenarios)}")
            print("=" * 60)
            
            results = await comparator.compare_responses(
                scenario['question'], 
                scenario['cities']
            )
            
            all_results.append({
                'scenario': i,
                'question': scenario['question'],
                'results': results
            })
            
            if i < len(test_scenarios):
                print("\\n‚è≥ Pause 3s...")
                await asyncio.sleep(3)
        
        # R√©sum√© global
        print(f"\\nüèÜ R√âSUM√â GLOBAL")
        print("=" * 60)
        
        if all_results and len(all_results[0]['results']) == 2:
            claude_times = [r['results']['claude']['time'] for r in all_results]
            azure_times = [r['results']['azure']['time'] for r in all_results]
            claude_lengths = [r['results']['claude']['length'] for r in all_results]
            azure_lengths = [r['results']['azure']['length'] for r in all_results]
            
            print(f"üìä STATISTIQUES:")
            print(f"   Claude - Temps moyen: {sum(claude_times)/len(claude_times):.2f}s")
            print(f"   Azure  - Temps moyen: {sum(azure_times)/len(azure_times):.2f}s")
            print(f"   Claude - Longueur moyenne: {sum(claude_lengths)/len(claude_lengths):.0f} chars")
            print(f"   Azure  - Longueur moyenne: {sum(azure_lengths)/len(azure_lengths):.0f} chars")
            
            claude_wins_speed = sum(1 for c, a in zip(claude_times, azure_times) if c < a)
            print(f"\\nüèÉ Vitesse: Claude gagne {claude_wins_speed}/{len(all_results)} fois")
        
        print(f"\\n‚úÖ COMPARAISON TERMIN√âE!")
        print(f"üéØ Les deux IA fonctionnent parfaitement avec votre serveur MCP!")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await comparator.cleanup()


if __name__ == "__main__":
    print(f"üîß Workspace: {os.getcwd()}")
    
    available_apis = []
    if claude_available and ANTHROPIC_LIB:
        available_apis.append("Claude")
    if azure_available and OPENAI_LIB:
        available_apis.append("Azure OpenAI")
    
    if available_apis:
        print(f"üéØ APIs disponibles: {', '.join(available_apis)}")
        try:
            asyncio.run(run_comparison())
        except KeyboardInterrupt:
            print("\\n‚ö†Ô∏è Comparaison interrompue par l'utilisateur")
        except Exception as e:
            print(f"\\n‚ùå Erreur g√©n√©rale: {e}")
    else:
        print("‚ùå Aucune API disponible pour la comparaison")
        print("üí° Configurez au moins une API dans .env et installez les d√©pendances")